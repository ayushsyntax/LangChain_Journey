{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUcOcraqJBdBah+vUQEtLk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ”‘ Key Concepts â€” Tool Calling in LangChain\n",
        "\n",
        "---\n",
        "\n",
        "## 1. LLMs Are Reasoning Engines, Not Executors\n",
        "\n",
        "* LLMs **cannot perform actions**\n",
        "* They only:\n",
        "\n",
        "  * interpret intent\n",
        "  * choose tools\n",
        "  * generate structured outputs\n",
        "* All execution happens **outside** the model\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Tools Are Explicit Capabilities\n",
        "\n",
        "A tool is:\n",
        "\n",
        "* A typed Python function\n",
        "* With a clear name\n",
        "* A descriptive docstring\n",
        "* A strict input schema\n",
        "\n",
        "Purpose:\n",
        "\n",
        "> Tell the LLM what it *can* do â€” not how to do it.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Tool Binding â‰  Tool Execution\n",
        "\n",
        "Binding:\n",
        "\n",
        "* Registers tools with the model\n",
        "* Makes them visible for reasoning\n",
        "* Does **not** run anything\n",
        "\n",
        "Think:\n",
        "\n",
        "> â€œThese are the tools you may request.â€\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Tool Calling Is a Suggestion, Not an Action\n",
        "\n",
        "When the LLM calls a tool:\n",
        "\n",
        "* It emits structured JSON\n",
        "* It does NOT execute the function\n",
        "* It expects the host application to decide what to do\n",
        "\n",
        "This is a critical safety boundary.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Execution Control Belongs to the Developer\n",
        "\n",
        "You:\n",
        "\n",
        "* Validate arguments\n",
        "* Run the function\n",
        "* Handle errors\n",
        "* Inject results back into the conversation\n",
        "\n",
        "This ensures:\n",
        "\n",
        "* Security\n",
        "* Determinism\n",
        "* Debuggability\n",
        "\n",
        "---\n",
        "\n",
        "## 6. InjectedToolArg Prevents Hallucination\n",
        "\n",
        "Used when:\n",
        "\n",
        "* Values must come from real computation\n",
        "* LLM should not guess (rates, tokens, IDs)\n",
        "\n",
        "It enforces:\n",
        "\n",
        "* Human or system-controlled data flow\n",
        "* Sequential tool execution\n",
        "* Correct dependency chaining\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Tool Calling Is Deterministic\n",
        "\n",
        "Unlike agents:\n",
        "\n",
        "* No hidden loops\n",
        "* No autonomous planning\n",
        "* No uncontrolled execution\n",
        "\n",
        "You explicitly control:\n",
        "\n",
        "* Order\n",
        "* Conditions\n",
        "* State\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Agents Are Built on Top of Tool Calling\n",
        "\n",
        "Tool calling = foundation\n",
        "Agent = orchestration layer\n",
        "\n",
        "Agents add:\n",
        "\n",
        "* Planning\n",
        "* Iteration\n",
        "* Memory\n",
        "* Autonomy\n",
        "\n",
        "But also:\n",
        "\n",
        "* More risk\n",
        "* Less predictability\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Separation of Concerns Is the Core Design Principle\n",
        "\n",
        "| Component        | Responsibility   |\n",
        "| ---------------- | ---------------- |\n",
        "| LLM              | Reasoning        |\n",
        "| Tool             | Execution        |\n",
        "| App Code         | Control & Safety |\n",
        "| Agent (optional) | Orchestration    |\n",
        "\n",
        "This separation is why LangChain scales to production.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. The Fundamental Mental Model\n",
        "\n",
        "```\n",
        "Think â†’ Decide â†’ Execute â†’ Observe â†’ Respond\n",
        "```\n",
        "\n",
        "* LLM â†’ Think & Decide\n",
        "* Tools â†’ Execute\n",
        "* App â†’ Coordinate\n",
        "* User â†’ Receive result\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aRV3j4ueDpMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  Tool Calling in LangChain â€” Architecture, Flow, and Implementation\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Conceptual Model â€” LLMs as Brains, Tools as Limbs\n",
        "\n",
        "Large Language Models are powerful **reasoning engines**, but they are **isolated from the external world**.\n",
        "\n",
        "They can:\n",
        "\n",
        "* Parse intent\n",
        "* Reason symbolically\n",
        "* Generate structured outputs\n",
        "\n",
        "They **cannot**:\n",
        "\n",
        "* Call APIs\n",
        "* Query databases\n",
        "* Access real-time data\n",
        "* Mutate external systems\n",
        "\n",
        "LangChain bridges this gap by introducing **Tools**, turning the LLM into a decision-maker rather than an executor.\n",
        "\n",
        "### High-Level Mental Model\n",
        "\n",
        "```\n",
        "User â†’ LLM (Reasoning) â†’ Tool Selection â†’ Tool Execution â†’ Result â†’ LLM â†’ Final Answer\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Visual Reference\n",
        "\n",
        "![LLM Tool Calling Flow](https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/tool_calling_overview.png)\n",
        "\n",
        "Source: LangChain Documentation\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Architectural Breakdown â€” The Four Stages\n",
        "\n",
        "---\n",
        "\n",
        "## I. Tool Definition (Capability Declaration)\n",
        "\n",
        "A **tool** is a typed, documented Python function exposed to the LLM.\n",
        "\n",
        "### Purpose\n",
        "\n",
        "* Describe *what* the tool does\n",
        "* Specify *how* it should be called\n",
        "* Restrict *what inputs* are valid\n",
        "\n",
        "### Implementation\n",
        "\n",
        "```python\n",
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "from langchain_core.tools.base import InjectedToolArg\n",
        "\n",
        "@tool\n",
        "def get_conversion_factor(base: str, target: str) -> float:\n",
        "    \"\"\"Fetches real-time conversion rate between two currencies.\"\"\"\n",
        "    return 85.34  # Placeholder for API result\n",
        "```\n",
        "\n",
        "### What the LLM Sees\n",
        "\n",
        "* Tool name\n",
        "* Natural language description\n",
        "* Typed argument schema\n",
        "\n",
        "This becomes part of the modelâ€™s **reasoning context**, not executable code.\n",
        "\n",
        "---\n",
        "\n",
        "## II. Tool Binding (Capability Registration)\n",
        "\n",
        "Binding exposes tools to the LLM.\n",
        "\n",
        "```python\n",
        "llm_with_tools = llm.bind_tools([\n",
        "    get_conversion_factor,\n",
        "    convert_currency\n",
        "])\n",
        "```\n",
        "\n",
        "### What Happens Internally\n",
        "\n",
        "* Tool metadata is serialized\n",
        "* Added to model prompt context\n",
        "* Model learns *what it can do*, not *when to do it*\n",
        "\n",
        "---\n",
        "\n",
        "### Visual Reference\n",
        "\n",
        "![Tool Binding Diagram](https://python.langchain.com/assets/images/tool_calling_sequence-9a1e8e5f4db3fd4bb5c4ed7b6e6ad3ff.png)\n",
        "\n",
        "Source: LangChain Docs\n",
        "\n",
        "---\n",
        "\n",
        "## III. Tool Calling (Decision Phase)\n",
        "\n",
        "The LLM now decides:\n",
        "\n",
        "> â€œI cannot answer this directly. I need a tool.â€\n",
        "\n",
        "### Example Prompt\n",
        "\n",
        "```\n",
        "Convert 10 USD to INR\n",
        "```\n",
        "\n",
        "### Model Output (Structured Tool Call)\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"get_conversion_factor\",\n",
        "  \"args\": {\n",
        "    \"base\": \"USD\",\n",
        "    \"target\": \"INR\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### Critical Detail\n",
        "\n",
        "âš ï¸ **The LLM does NOT execute anything.**\n",
        "\n",
        "It only *proposes* the call.\n",
        "\n",
        "Execution is strictly controlled by your code.\n",
        "\n",
        "---\n",
        "\n",
        "## IV. Tool Execution (Controlled Runtime)\n",
        "\n",
        "You now:\n",
        "\n",
        "1. Read the tool call\n",
        "2. Execute the function\n",
        "3. Inject results back into the conversation\n",
        "\n",
        "```python\n",
        "result_msg = get_conversion_factor.invoke(tool_call)\n",
        "messages.append(result_msg)\n",
        "```\n",
        "\n",
        "This keeps:\n",
        "\n",
        "* Determinism\n",
        "* Security boundaries\n",
        "* Auditable execution\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Injected Tool Arguments (Sequential Tooling)\n",
        "\n",
        "Some values must **never** be guessed by the model.\n",
        "\n",
        "Example:\n",
        "\n",
        "* Exchange rates\n",
        "* Tokens\n",
        "* Secrets\n",
        "* API outputs\n",
        "\n",
        "### Solution: `InjectedToolArg`\n",
        "\n",
        "```python\n",
        "@tool\n",
        "def convert_currency(\n",
        "    amount: int,\n",
        "    rate: Annotated[float, InjectedToolArg]\n",
        ") -> float:\n",
        "    return amount * rate\n",
        "```\n",
        "\n",
        "### Behavior\n",
        "\n",
        "* LLM cannot hallucinate `rate`\n",
        "* Developer must inject it manually\n",
        "* Enables multi-step workflows\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Full Execution Flow (End-to-End)\n",
        "\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "    User->>LLM: Convert 10 USD to INR\n",
        "    LLM->>Tool: get_conversion_factor(USD, INR)\n",
        "    Tool-->>App: 85.34\n",
        "    App->>Tool: convert_currency(10, 85.34)\n",
        "    Tool-->>LLM: 853.4\n",
        "    LLM-->>User: Final Answer\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Production-Grade Execution Loop\n",
        "\n",
        "```python\n",
        "messages = [HumanMessage(content=\"Convert 10 USD to INR\")]\n",
        "\n",
        "ai_msg = llm_with_tools.invoke(messages)\n",
        "messages.append(ai_msg)\n",
        "\n",
        "for call in ai_msg.tool_calls:\n",
        "    if call[\"name\"] == \"get_conversion_factor\":\n",
        "        result = get_conversion_factor.invoke(call)\n",
        "        messages.append(result)\n",
        "        rate = result.content[\"rate\"]\n",
        "\n",
        "    elif call[\"name\"] == \"convert_currency\":\n",
        "        call[\"args\"][\"rate\"] = rate\n",
        "        result = convert_currency.invoke(call)\n",
        "        messages.append(result)\n",
        "\n",
        "final = llm_with_tools.invoke(messages)\n",
        "print(final.content)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Agent vs Tool Calling â€” Critical Distinction\n",
        "\n",
        "| Feature        | Tool Calling  | Agent         |\n",
        "| -------------- | ------------- | ------------- |\n",
        "| Control Flow   | Manual        | Autonomous    |\n",
        "| Safety         | High          | Medium        |\n",
        "| Predictability | Deterministic | Probabilistic |\n",
        "| Debugging      | Easy          | Complex       |\n",
        "| Production Use | Preferred     | Selective     |\n",
        "\n",
        "---\n",
        "\n",
        "### Analogy\n",
        "\n",
        "* **Tool Calling** â†’ Aircraft autopilot with manual override\n",
        "* **Agent** â†’ Fully autonomous drone\n",
        "\n",
        "Tool calling gives:\n",
        "\n",
        "* Auditability\n",
        "* Determinism\n",
        "* Enterprise safety\n",
        "\n",
        "Agents give:\n",
        "\n",
        "* Autonomy\n",
        "* Exploration\n",
        "* Higher failure surface\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Best Practices (Production)\n",
        "\n",
        "âœ” Use deterministic tools\n",
        "âœ” Enforce schema validation\n",
        "âœ” Never let LLM execute code\n",
        "âœ” Log all tool calls\n",
        "âœ” Separate reasoning from execution\n",
        "âœ” Use injected arguments for sensitive data\n",
        "âœ” Version tools like APIs\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Authoritative References\n",
        "\n",
        "* LangChain Tool Calling Docs\n",
        "  [https://python.langchain.com/docs/modules/agents/tools/](https://python.langchain.com/docs/modules/agents/tools/)\n",
        "\n",
        "* OpenAI Function Calling Spec\n",
        "  [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)\n",
        "\n",
        "* JSON Schema\n",
        "  [https://json-schema.org/](https://json-schema.org/)\n",
        "\n",
        "* NIST Secure Software Development Framework\n",
        "  [https://csrc.nist.gov/publications/detail/sp/800-218/final](https://csrc.nist.gov/publications/detail/sp/800-218/final)\n",
        "\n",
        "---\n",
        "\n",
        "## Final Summary\n",
        "\n",
        "Tool calling turns LLMs from **text generators** into **decision engines**.\n",
        "\n",
        "The LLM:\n",
        "\n",
        "* Thinks\n",
        "* Plans\n",
        "* Selects tools\n",
        "\n",
        "Your code:\n",
        "\n",
        "* Executes\n",
        "* Verifies\n",
        "* Secures\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hm3lAt9uB5za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  **The Fundamental Role of Tools**\n",
        "\n",
        "To understand tool calling, one must first recognize the inherent nature of Large Language Models (LLMs). LLMs possess two primary \"powers\":\n",
        "\n",
        "### ðŸ§  **LLM Capabilities:**\n",
        "- **Reasoning** ðŸ§© - Breaks down and understands questions\n",
        "- **Output Generation** âœï¸ - Produces text based on parametric knowledge\n",
        "\n",
        "> **ðŸ’¡ Think of an LLM as:** A human who is excellent at thinking and speaking but lacks \"hands and feet\" to perform physical or software-based tasks.\n",
        "\n",
        "### ðŸš« **What LLMs Cannot Do Alone:**\n",
        "- âŒ Update a database\n",
        "- âŒ Post to social media  \n",
        "- âŒ Hit an API to check live weather\n",
        "- âŒ Check currency rates\n",
        "\n",
        "### ðŸ”— **The Solution: Tool Calling**\n",
        "**Tools** = Python functions designed to carry out specific tasks  \n",
        "**Tool Calling** = Critical bridge connecting reasoning brains to functional \"limbs\"\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”„ **The Tool Calling Workflow: Step-by-Step**\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[User Query] --> B[Tool Creation]\n",
        "    B --> C[Tool Binding]\n",
        "    C --> D[Tool Call]\n",
        "    D --> E[Tool Execution]\n",
        "    E --> F[Final Generation]\n",
        "    F --> G[Response to User]\n",
        "```\n",
        "\n",
        "### **Step 1: ðŸ› ï¸ Tool Creation**\n",
        "Tools are created using the `@tool` decorator in Python:\n",
        "\n",
        "```python\n",
        "@tool\n",
        "def weather_search(city: str) -> str:\n",
        "    \"\"\"Search for current weather in a given city\"\"\"\n",
        "    # Implementation here\n",
        "```\n",
        "\n",
        "#### **Required Attributes:**\n",
        "- **Name** ðŸ·ï¸ - Unique identifier for the tool\n",
        "- **Description** ðŸ“ - Text explanation for LLM understanding\n",
        "- **Input Schema** ðŸ“‹ - Format and types of expected input\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2: ðŸ“Œ Tool Binding**\n",
        "Register tools to the LLM using `bind_tools()`:\n",
        "\n",
        "```python\n",
        "bound_llm = llm.bind_tools([weather_tool, search_tool])\n",
        "```\n",
        "\n",
        "This notifies the LLM of:\n",
        "- Available tools\n",
        "- Their purposes (via descriptions)\n",
        "- Required input formats\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3: ðŸŽ¯ The Tool Call (Reasoning Step)**\n",
        "\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "    participant User as User\n",
        "    participant LLM as LLM\n",
        "    participant Tool as Tool\n",
        "    \n",
        "    User->>LLM: Query \"What's the weather in Tokyo?\"\n",
        "    alt Needs Tool\n",
        "        LLM->>LLM: Generate Tool Call\n",
        "        Note over LLM: Tool: weather_search(city=\"Tokyo\")\n",
        "    else No Tool Needed\n",
        "        LLM->>User: Direct response\n",
        "    end\n",
        "```\n",
        "\n",
        "#### **Key Points:**\n",
        "- âŒ LLM does **NOT** execute the tool\n",
        "- âœ… LLM generates **structured output** (Tool Call)\n",
        "- Includes: **Tool Name** + **Arguments needed**\n",
        "- Simple queries get direct text responses\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 4: âš¡ Tool Execution (Action Step)**\n",
        "\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "    participant LLM as LLM\n",
        "    participant Programmer as Programmer\n",
        "    participant Tool as Tool\n",
        "    \n",
        "    LLM->>Programmer: Tool Call suggestion\n",
        "    Programmer->>Tool: Execute with arguments\n",
        "    Tool->>Programmer: Tool Message (result)\n",
        "    Programmer->>LLM: Send result back\n",
        "```\n",
        "\n",
        "#### **Security Feature:**\n",
        "- Tool execution handled by **programmer/framework**\n",
        "- Prevents LLM from running potentially risky code\n",
        "- Maintains security and control\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 5: ðŸŽ‰ Final Generation**\n",
        "\n",
        "#### **Conversation History:**\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ ðŸ§‘ Human Message: \"Weather in Tokyo?\" â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ðŸ¤– AI Message: [Tool Call: weather_search(city=\"Tokyo\")] â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ðŸ› ï¸ Tool Message: \"72Â°F, Sunny\"      â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "The LLM generates a human-friendly final response based on tool results.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ **Advanced Implementation: Handling Dependencies**\n",
        "\n",
        "### **The Problem: ðŸ¤” Hallucination Issue**\n",
        "\n",
        "**Scenario:** Convert 10 USD to INR\n",
        "\n",
        "```python\n",
        "# âŒ Problem: LLM guesses conversion rate\n",
        "conversion_rate = 73.73  # Wrong! (Actual: 85.34)\n",
        "```\n",
        "\n",
        "**Why this happens:** LLM tries to fill all arguments before dependent tools run.\n",
        "\n",
        "---\n",
        "\n",
        "### **The Solution: ðŸ’‰ InjectedToolArg**\n",
        "\n",
        "```python\n",
        "from langchain_core.tools import InjectedToolArg\n",
        "\n",
        "@tool\n",
        "def convert_currency(\n",
        "    amount: float,\n",
        "    from_currency: str,\n",
        "    to_currency: str,\n",
        "    conversion_rate: float = InjectedToolArg()  # â­ Injected!\n",
        "):\n",
        "    \"\"\"Convert currency with real-time rate\"\"\"\n",
        "    return amount * conversion_rate\n",
        "```\n",
        "\n",
        "#### **Multi-Step Logic:**\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "    A[LLM suggests: Get Conversion Factor] --> B[Programmer executes first tool]\n",
        "    B --> C[LLM suggests: Convert Currency<br/>LEAVES rate EMPTY]\n",
        "    C --> D[Programmer injects real rate<br/>and executes conversion]\n",
        "    D --> E[Final response with accurate conversion]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¤– **Tool Calling vs. AI Agents**\n",
        "\n",
        "### **Manual Tool Calling ðŸ“‹**\n",
        "```\n",
        "Programmer writes logic for:\n",
        "â”œâ”€â”€ Loop through tool calls\n",
        "â”œâ”€â”€ Execute tools\n",
        "â””â”€â”€ Feed results back to LLM\n",
        "```\n",
        "\n",
        "### **AI Agents ðŸ¤– (Autonomous)**\n",
        "```\n",
        "Agent receives goal â†’\n",
        "â”œâ”€â”€ Independently decides tool sequence\n",
        "â”œâ”€â”€ Manages execution order\n",
        "â””â”€â”€ No manual intervention needed\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ³ **Understanding Analogy**\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "    A[LLM = Chef] --> B[Has recipe but can't move]\n",
        "    B --> C[Programmer = Kitchen Assistant]\n",
        "    C --> D[User: \"Make soup with fresh onions\"]\n",
        "    D --> E[Chef: \"I need chopped onions\" ðŸ› ï¸]\n",
        "    E --> F[Assistant gets & chops onions âœ…]\n",
        "    F --> G[Assistant brings to chef ðŸ› ï¸]\n",
        "    G --> H[Chef completes soup ðŸ²]\n",
        "    \n",
        "    style A fill:#e1f5fe\n",
        "    style C fill:#f3e5f5\n",
        "    style E fill:#fff3e0\n",
        "    style F fill:#e8f5e8\n",
        "```\n",
        "\n",
        "### **For True AI Agents:**\n",
        "> The chef (LLM) would be allowed to move around and perform all actions independently.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ **Key Takeaways**\n",
        "\n",
        "| **Aspect** | **Manual Tool Calling** | **AI Agent** |\n",
        "|------------|------------------------|--------------|\n",
        "| **Control** | Programmer-controlled | Autonomous |\n",
        "| **Decision** | Manual steps | Self-directed |\n",
        "| **Complexity** | More code required | Framework handles |\n",
        "| **Flexibility** | Maximum control | Built-in patterns |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1Wg7I9NRCWSj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNprK-qwB-Ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}