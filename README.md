# ðŸ§  LangChain Journey  
*by ayushsyntax*

> *A personal learning lab where I explore LangChain concepts, RAG pipelines, and agent workflows through hands-on experiments.*

---

## ðŸ” What This Is

This is my **working notebook repository** â€” not a polished library or tutorial.  
I built it to:

- âœ… Learn by doing: Each `.ipynb` starts with a question I wanted to answer.
- âœ… Document my path: From â€œHow do I call a model?â€ to â€œHow do I build an agent?â€
- âœ… Keep what worked â€” and what broke: Failures are annotated, not deleted.
- âœ… Create a reference I can revisit when I forget how `RunnableParallel` works.

No corporate speak. No â€œrevolutionaryâ€ claims. Just code, notes, and progress.

---

## ðŸ—‚ï¸ How Itâ€™s Organized

```
LangChain_Journey/
â”‚
â”œâ”€â”€ ðŸ—ï¸ core/             # Foundations
â”‚   â”œâ”€â”€ Introduction_to_LangChain.ipynb     # First steps
â”‚   â”œâ”€â”€ Models_1.ipynb                       # Calling LLMs & ChatModels
â”‚   â””â”€â”€ Prompts_2.ipynb                      # Templates, roles, dynamic prompts
â”‚
â”œâ”€â”€ â›“ï¸ orchestration/    # Chaining & Flow
â”‚   â”œâ”€â”€ Chains_in_LangChain_5.ipynb          # LCEL basics
â”‚   â”œâ”€â”€ What_are_Runnables_6.ipynb           # Standard invoke() interface
â”‚   â””â”€â”€ Output_Parsers_4.ipynb               # Pydantic, StringOutputParser
â”‚
â”œâ”€â”€ ðŸ“‘ data/              # Loading & Structuring
â”‚   â”œâ”€â”€ Document_Loaders_RAG1.ipynb          # PDF, Web, CSV â†’ Documents
â”‚   â”œâ”€â”€ Text_Splitters_RAG2.ipynb            # Chunking for context limits
â”‚   â””â”€â”€ Vector_Stores_RAG3.ipynb             # Embeddings + Chroma/FAISS
â”‚
â”œâ”€â”€ ðŸ” rag/               # Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ Retrievers_RAG4.ipynb                # Semantic search, MMR, compression
â”‚   â””â”€â”€ RAG_Pipeline_Complete.ipynb          # End-to-end implementation
â”‚
â””â”€â”€ ðŸ¤– agents/            # Tool Calling & Autonomous Workflows
    â”œâ”€â”€ Tools_Calling_in_LangChain.ipynb     # @tool, binding, safe execution
    â””â”€â”€ Building_end_to_end_AI_Agent.ipynb   # ReAct loop with AgentExecutor
```

---

## ðŸ§© Key Concepts Iâ€™ve Implemented

### 1. **Models & Prompts**
- Learned difference between `LLM` (string-in/string-out) and `ChatModel` (message-based)
- Used `ChatPromptTemplate` with `SystemMessage`, `HumanMessage`, `AIMessage`
- Controlled output randomness with `temperature=0` (deterministic) vs `temperature=1.5` (creative)

â†’ [`Models_1.ipynb`](Models_1.ipynb) Â· [`Prompts_2.ipynb`](Prompts_2.ipynb)

### 2. **Runnables & LCEL**
- Understood `Runnable` interface â€” everything has `.invoke()`
- Built chains with `|` operator: `prompt | model | parser`
- Used `RunnableParallel` to fetch context + pass original question simultaneously

â†’ [`What_are_Runnables_6.ipynb`](What_are_Runnables_6.ipynb) Â· [`Chains_in_LangChain_5.ipynb`](Chains_in_LangChain_5.ipynb)

### 3. **Structured Output**
- Used `PydanticOutputParser` to enforce schema (e.g., `age: int > 0`)
- Injected format instructions into prompts via `partial_variables`
- Prevented hallucinations by validating output before use

â†’ [`Output_Parsers_4.ipynb`](Output_Parsers_4.ipynb)

### 4. **RAG Pipeline**
```mermaid
flowchart LR
    Q[Query] --> E[Embed]
    Docs[Documents] --> S[Splitter]
    S --> E2[Embed Chunks]
    E --> VS[Vector Store]
    E2 --> VS
    VS --> R[Retrieve Top-k]
    R --> Aug[â€œAnswer ONLY using context:â€ + context + query]
    Aug --> LLM
    LLM --> Ans[Final Answer]
    
    classDef process fill:#673AB7,stroke:#4527A0,color:white
    classDef data fill:#FF9800,stroke:#EF6C00,color:black
    
    class E,S,E2,R,Aug,LLM process
    class Docs,Q,Ans data
```
- Used `RecursiveCharacterTextSplitter` to preserve sentence boundaries
- Added `ContextualCompressionRetriever` to trim irrelevant text before LLM input

â†’ [`RAG_Pipeline_Complete.ipynb`](RAG_Pipeline_Complete.ipynb)

### 5. **Agents & Tools**
```mermaid
stateDiagram-v2
    [*] --> Think
    Think --> Act: â€œCall get_weather(â€˜Delhiâ€™)â€
    Act --> Observe: Returns â€œ32Â°C, Partly Cloudyâ€
    Observe --> Decide
    Decide --> Think: â€œNeed humidity?â€
    Decide --> Answer: â€œItâ€™s hot. Wear light clothes.â€
    Answer --> [*]
    
    note right of Observe
      The LLM suggests the tool.
      The framework runs it.
      Safety first.
    end note
```
- Defined tools with `@tool` decorator
- Bound tools to model with `model.bind_tools([get_weather])`
- Used `AgentExecutor` for simple ReAct loops (no LangGraph yet)

â†’ [`Tools_Calling_in_LangChain.ipynb`](Tools_Calling_in_LangChain.ipynb) Â· [`Building_end_to_end_AI_Agent.ipynb`](Building_end_to_end_AI_Agent.ipynb)

---

## ðŸ› ï¸ My Setup

| Component | Choice |
|----------|--------|
| **LangChain** | v1.0 (core only â€” no LangGraph yet) |
| **Python** | 3.14.2 |
| **Environment** | JupyterLab 4.x |
| **Models** | OpenAI (`gpt-4o`), Ollama (`llama3.1`) |
| **Vector DB** | Chroma (local), FAISS (for testing) |

> âœ… All notebooks run locally  
> âœ… Code comments explain *why*, not just *how*  
> âœ… Failed attempts are kept â€” with notes on what went wrong

---

## ðŸ“œ A Note to My Future Self

> *When you come back here:*  
> - Donâ€™t skip the messy cells. Thatâ€™s where you figured things out.  
> - Re-read the `agent_executor.ipynb` failures â€” they taught you about tool safety.  
> - Remember how `RunnableParallel` clicked when you needed to pass the original question.  
>  
> Youâ€™re not done. Youâ€™re just getting started.  
> â€” Current You

---

<div align="center">

[![Open in GitHub](https://img.shields.io/badge/GitHub-Explore_Repo-181717?logo=github&logoColor=white)](https://github.com/ayushsyntax/LangChain_Journey)  
**LangChain isnâ€™t magic. Itâ€™s patterns.  
This is where Iâ€™m learning them.**

</div>
